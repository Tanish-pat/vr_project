{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "714dd15a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T08:56:51.802543Z",
     "iopub.status.busy": "2025-05-17T08:56:51.801967Z",
     "iopub.status.idle": "2025-05-17T08:56:55.766415Z",
     "shell.execute_reply": "2025-05-17T08:56:55.765606Z"
    },
    "papermill": {
     "duration": 3.96929,
     "end_time": "2025-05-17T08:56:55.767739",
     "exception": false,
     "start_time": "2025-05-17T08:56:51.798449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a359e1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T08:56:55.773152Z",
     "iopub.status.busy": "2025-05-17T08:56:55.772872Z",
     "iopub.status.idle": "2025-05-17T08:56:55.782309Z",
     "shell.execute_reply": "2025-05-17T08:56:55.781545Z"
    },
    "papermill": {
     "duration": 0.013327,
     "end_time": "2025-05-17T08:56:55.783494",
     "exception": false,
     "start_time": "2025-05-17T08:56:55.770167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 42.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "print(\"Random seed set to 42.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2609373e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T08:56:55.788525Z",
     "iopub.status.busy": "2025-05-17T08:56:55.788071Z",
     "iopub.status.idle": "2025-05-17T08:56:56.150448Z",
     "shell.execute_reply": "2025-05-17T08:56:56.149682Z"
    },
    "papermill": {
     "duration": 0.366175,
     "end_time": "2025-05-17T08:56:56.151737",
     "exception": false,
     "start_time": "2025-05-17T08:56:55.785562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 JSON files.\n",
      "Sample JSON file paths: ['/kaggle/input/zero-shot-dataset/zero_shot_dataset/010-mllS7JL.json', '/kaggle/input/zero-shot-dataset/zero_shot_dataset/21-GDjbU0yL.json']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Paths\n",
    "json_path = \"/kaggle/input/zero-shot-dataset/zero_shot_dataset\"  \n",
    "image_dir = \"/kaggle/input/berkley-dataset/\"  \n",
    "\n",
    "# Check JSON files\n",
    "json_files = sorted(glob(os.path.join(json_path, \"*.json\")))\n",
    "print(f\"Found {len(json_files)} JSON files.\")\n",
    "print(\"Sample JSON file paths:\", json_files[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50b4206c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T08:56:56.156938Z",
     "iopub.status.busy": "2025-05-17T08:56:56.156737Z",
     "iopub.status.idle": "2025-05-17T08:58:02.573091Z",
     "shell.execute_reply": "2025-05-17T08:58:02.572372Z"
    },
    "papermill": {
     "duration": 66.420541,
     "end_time": "2025-05-17T08:58:02.574537",
     "exception": false,
     "start_time": "2025-05-17T08:56:56.153996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\r\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\r\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\r\n",
      "Collecting bert-score\r\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\r\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\r\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\r\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\r\n",
      "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\r\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\r\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.5.1+cu124)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score) (3.7.5)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.2)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.6)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.0.0->bert-score)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.0.0->bert-score)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.0.0->bert-score)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.0.0->bert-score)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.0.0->bert-score)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.0.0->bert-score)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.0.0->bert-score)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (4.56.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.4.8)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (3.2.1)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\r\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bert-score\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\r\n",
      "  Attempting uninstall: fsspec\r\n",
      "    Found existing installation: fsspec 2025.3.2\r\n",
      "    Uninstalling fsspec-2025.3.2:\r\n",
      "      Successfully uninstalled fsspec-2025.3.2\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\r\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed bert-score-0.3.13 fsspec-2024.12.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\r\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "!pip install tqdm transformers datasets bert-score tqdm Pillow sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be65ecfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T08:58:02.611927Z",
     "iopub.status.busy": "2025-05-17T08:58:02.611312Z",
     "iopub.status.idle": "2025-05-17T08:59:50.199263Z",
     "shell.execute_reply": "2025-05-17T08:59:50.198425Z"
    },
    "papermill": {
     "duration": 107.607686,
     "end_time": "2025-05-17T08:59:50.200540",
     "exception": false,
     "start_time": "2025-05-17T08:58:02.592854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSON files: 100%|██████████| 25000/25000 [01:47<00:00, 232.39file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total question-answer pairs across all files: 374828\n",
      "Total malformed QA pairs skipped: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# List to store all QA pairs across all files in the desired format\n",
    "qa_data_all = []\n",
    "\n",
    "# Counter for malformed QA pairs\n",
    "missing_count = 0\n",
    "\n",
    "# Process each JSON file separately\n",
    "for selected_json in tqdm(json_files, desc=\"Processing JSON files\", unit=\"file\"):\n",
    "    with open(selected_json, 'r') as f:\n",
    "        dataset = json.load(f)\n",
    "\n",
    "    for i in range(0, len(dataset), 2):\n",
    "        image_entry = dataset[i]\n",
    "        questions_entry = dataset[i + 1] if i + 1 < len(dataset) else {}\n",
    "\n",
    "        image_path = image_entry.get(\"path\", \"\")\n",
    "\n",
    "        if image_dir and not os.path.isabs(image_path):\n",
    "            image_path = os.path.join(image_dir, image_path.lstrip(\"/\").lstrip(\"../\"))\n",
    "\n",
    "        questions = questions_entry.get(\"questions\", [])\n",
    "        for qa_pair in questions:\n",
    "            qa_pair = {k.strip(): v for k, v in qa_pair.items()}\n",
    "\n",
    "            if \"question\" in qa_pair and \"answer\" in qa_pair:\n",
    "                qa_data_all.append({\n",
    "                    \"image_path\": image_path,\n",
    "                    \"question\": qa_pair[\"question\"],\n",
    "                    \"answer\": qa_pair[\"answer\"]\n",
    "                })\n",
    "            else:\n",
    "                missing_count += 1\n",
    "                print(f\"\\nMalformed QA pair in file: {selected_json}\")\n",
    "                print(f\"  Image path: {image_path}\")\n",
    "                print(f\"  Raw entry: {qa_pair}\")\n",
    "\n",
    "# Summary\n",
    "total_qa_pairs = len(qa_data_all)\n",
    "print(f\"\\nTotal question-answer pairs across all files: {total_qa_pairs}\")\n",
    "print(f\"Total malformed QA pairs skipped: {missing_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1d9a783",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T08:59:50.312332Z",
     "iopub.status.busy": "2025-05-17T08:59:50.311708Z",
     "iopub.status.idle": "2025-05-17T09:01:41.374123Z",
     "shell.execute_reply": "2025-05-17T09:01:41.373500Z"
    },
    "papermill": {
     "duration": 111.118737,
     "end_time": "2025-05-17T09:01:41.375311",
     "exception": false,
     "start_time": "2025-05-17T08:59:50.256574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-17 08:59:58.670889: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747472398.857132      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747472398.910914      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620555c68a1745e69b5a447654309d79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6818d20bec34ad7bee09111f2398925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85fd1381da36453ab4f45b3c00c47e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c154fa1c86247b7afe78842234922bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b4e8736539d422cbd771edf69801f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de806421cb5d449c88993bea6d6ecd25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd9c75a645d847e5890f16998723c188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a592fe1ab4e94968a87841513f882573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1495401e2acf4f8a9fb9a39da49e0e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad14de8ca0b44b0bf3d612c4030af54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db881890c38f4d5e8d1de65b18865f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69ca7513a4241beaba1dcc10ddefb32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/432 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3805219571341108d0466fc2fa5b77b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/882 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b383383d9cb042618927b3613d6c86eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f52fcbac8fa4bb9a1cc1761674e578c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1088e2a557474e2a84f903f6df0b949a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.56M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e0285287134ea6bcac72e2da2fb780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9764554912479b963b4dab4f322e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/548 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8f0380adae47d494e193de439a57e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processor_config.json:   0%|          | 0.00/68.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83edf7fa4a3042debfb972f4c76fc531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ee8f8c4fd14eb48cdd5494fd1d9fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/122k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07497e3ad9ed4ae7ac48cc3ada4445f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c70dada0ec2457288bf8a2ab529dd53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/10.0G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3860a2290bd446a2945c030c23acf7a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99076a884cbd42d6b1ba9a15da381a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af9c0baebb24ab0a9caa09b32e73632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/141 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ BLIP-2 model and SentenceTransformer loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration, logging\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Suppress unnecessary warnings\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# Device setup\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load Sentence Transformer (for semantic similarity)\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2').to(device)\n",
    "\n",
    "# Load BLIP-2 VQA model and processor\n",
    "model_name = \"Salesforce/blip2-opt-2.7b\"\n",
    "processor = Blip2Processor.from_pretrained(model_name)\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ").eval()\n",
    "\n",
    "print(\"✅ BLIP-2 model and SentenceTransformer loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faaf7ca2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T09:01:41.492108Z",
     "iopub.status.busy": "2025-05-17T09:01:41.491861Z",
     "iopub.status.idle": "2025-05-17T09:01:41.504041Z",
     "shell.execute_reply": "2025-05-17T09:01:41.503479Z"
    },
    "papermill": {
     "duration": 0.071102,
     "end_time": "2025-05-17T09:01:41.505071",
     "exception": false,
     "start_time": "2025-05-17T09:01:41.433969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader ready with 23427 batches!\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "class VQADataset(Dataset):\n",
    "    def __init__(self, qa_list, processor, cache_dir=None):\n",
    "        \n",
    "        self.qa = qa_list\n",
    "        self.processor = processor\n",
    "        self.cache_dir = cache_dir\n",
    "        \n",
    "        if self.cache_dir and not os.path.exists(self.cache_dir):\n",
    "            os.makedirs(self.cache_dir)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.qa)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        rec = self.qa[idx]\n",
    "        img_path = rec[\"image_path\"]\n",
    "        \n",
    "        if self.cache_dir:\n",
    "            cache_path = os.path.join(self.cache_dir, f\"{os.path.basename(img_path)}.pkl\")\n",
    "            if os.path.exists(cache_path):\n",
    "                try:\n",
    "                    with open(cache_path, 'rb') as f:\n",
    "                        img = pickle.load(f)\n",
    "                    return img, rec[\"question\"], rec[\"answer\"], rec[\"image_path\"]\n",
    "                except Exception:\n",
    "                    pass  \n",
    "        \n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.cache_dir:\n",
    "            try:\n",
    "                with open(cache_path, 'wb') as f:\n",
    "                    pickle.dump(img, f)\n",
    "            except Exception:\n",
    "                pass  \n",
    "                \n",
    "        return img, rec[\"question\"], rec[\"answer\"], rec[\"image_path\"]\n",
    "\n",
    "def collate_fn(batch):\n",
    "\n",
    "    imgs, questions, gts, paths = zip(*batch)\n",
    "    \n",
    "    try:\n",
    "        encoding = processor(\n",
    "            images=list(imgs),\n",
    "            text=list(questions),\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Processor error: {e}\")\n",
    "        first_good_batch = next((i for i, img in enumerate(imgs) if img is not None), 0)\n",
    "        encoding = processor(\n",
    "            images=[imgs[first_good_batch]],\n",
    "            text=[questions[first_good_batch]],\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        gts = [gts[first_good_batch]]\n",
    "        paths = [paths[first_good_batch]]\n",
    "        \n",
    "    return encoding, gts, paths\n",
    "\n",
    "def create_dataloader(qa_data, processor, batch_size=16, num_workers=4, \n",
    "                     cache_dir=\"./image_cache\", resume_from=0):\n",
    "\n",
    "    if resume_from > 0:\n",
    "        qa_data = qa_data[resume_from:]\n",
    "        \n",
    "    dataset = VQADataset(qa_data, processor, cache_dir=cache_dir)\n",
    "    \n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=collate_fn,\n",
    "        persistent_workers=True,\n",
    "        pin_memory=True,\n",
    "        prefetch_factor=2,  \n",
    "        drop_last=False,   \n",
    "    )\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 4\n",
    "CACHE_DIR = \"./image_cache\"\n",
    "\n",
    "resume_idx = 0\n",
    "if os.path.exists(\"resume_state.pkl\"):\n",
    "    with open(\"resume_state.pkl\", \"rb\") as f:\n",
    "        resume_state = pickle.load(f)\n",
    "        resume_idx = resume_state.get(\"last_processed_idx\", 0)\n",
    "        print(f\"Resuming from index {resume_idx}\")\n",
    "\n",
    "loader = create_dataloader(\n",
    "    qa_data_all, \n",
    "    processor,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    cache_dir=CACHE_DIR,\n",
    "    resume_from=resume_idx\n",
    ")\n",
    "\n",
    "print(f\"DataLoader ready with {len(loader)} batches!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60d5e4a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T09:01:41.620174Z",
     "iopub.status.busy": "2025-05-17T09:01:41.619818Z"
    },
    "papermill": {
     "duration": 1.059464,
     "end_time": "2025-05-17T09:01:42.621297",
     "exception": false,
     "start_time": "2025-05-17T09:01:41.561833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation of 23427 batches...\n",
      "Results will be saved to vqa_evaluation_results.csv, vqa_evaluation_results.json, and vqa_metrics.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521babe9339f491fb646f4fe132dda55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/23427 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from bert_score import score as bert_score\n",
    "from sentence_transformers import util\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# ─── ENHANCED CONFIG ────────────────────────────────────────────────────────────\n",
    "PRINT_LIMIT = 20     # how many samples to print\n",
    "BATCH_SIZE = 16      # Should match the batch size in your DataLoader\n",
    "DEVICE = device\n",
    "PROCESSOR = processor\n",
    "MODEL = model.eval()\n",
    "SENT_MODEL = sentence_model\n",
    "RESULTS_CSV = \"vqa_evaluation_results.csv\"\n",
    "RESULTS_JSON = \"vqa_evaluation_results.json\"  # New JSON format for complete data\n",
    "METRICS_NPZ = \"vqa_metrics.npz\"  # NumPy compressed format for numerical metrics\n",
    "\n",
    "# Note: The loader is already created in the previous code\n",
    "# loader = create_dataloader(...) from your previous code block\n",
    "\n",
    "# Initialize accumulators\n",
    "all_em = []\n",
    "all_f1_tok = []\n",
    "all_bert_p = []\n",
    "all_bert_r = []\n",
    "all_bert_f1 = []\n",
    "all_sent = []\n",
    "all_cos = []\n",
    "printed = 0\n",
    "sample_data = []  # Store full sample data for later analysis\n",
    "\n",
    "# No need to handle previous results anymore since we've removed the checkpointing\n",
    "\n",
    "# Helper function to save results in multiple formats\n",
    "def save_results():\n",
    "    \"\"\"Save evaluation results in multiple formats for later analysis\"\"\"\n",
    "    \n",
    "    # 1. Save detailed CSV with per-sample metrics\n",
    "    df = pd.DataFrame(sample_data)\n",
    "    df.to_csv(RESULTS_CSV, index=False)\n",
    "    \n",
    "    # 2. Save numerical metrics in NumPy compressed format (efficient for loading arrays)\n",
    "    np.savez(\n",
    "        METRICS_NPZ,\n",
    "        exact_match=np.array(all_em),\n",
    "        f1_token=np.array(all_f1_tok),\n",
    "        bert_p=np.array(all_bert_p),\n",
    "        bert_r=np.array(all_bert_r),\n",
    "        bert_f1=np.array(all_bert_f1),\n",
    "        sent_sim=np.array(all_sent),\n",
    "        cos_sim=np.array(all_cos)\n",
    "    )\n",
    "    \n",
    "    # 3. Save complete data in JSON format (human-readable and includes text)\n",
    "    all_data = {\n",
    "        \"samples\": sample_data,\n",
    "        \"summary\": {\n",
    "            \"exact_match\": float(np.mean(all_em)),\n",
    "            \"f1_token\": float(np.mean(all_f1_tok)),\n",
    "            \"bert_p\": float(np.mean(all_bert_p)),\n",
    "            \"bert_r\": float(np.mean(all_bert_r)),\n",
    "            \"bert_f1\": float(np.mean(all_bert_f1)),\n",
    "            \"sent_sim\": float(np.mean(all_sent)),\n",
    "            \"cos_sim\": float(np.mean(all_cos)),\n",
    "            \"total_samples\": len(all_em)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(RESULTS_JSON, 'w') as f:\n",
    "        json.dump(all_data, f)\n",
    "    \n",
    "    # 4. Also save summary stats\n",
    "    summary_df = pd.DataFrame({\n",
    "        \"metric\": [\"Exact Match\", \"Token F1\", \"BERT-P\", \"BERT-R\", \"BERT-F1\", \"Sent Sim\", \"Cos Sim\"],\n",
    "        \"value\": [\n",
    "            np.mean(all_em),\n",
    "            np.mean(all_f1_tok),\n",
    "            np.mean(all_bert_p),\n",
    "            np.mean(all_bert_r),\n",
    "            np.mean(all_bert_f1),\n",
    "            np.mean(all_sent),\n",
    "            np.mean(all_cos)\n",
    "        ]\n",
    "    })\n",
    "    summary_df.to_csv(\"vqa_summary_metrics.csv\", index=False)\n",
    "    \n",
    "    print(f\"Results saved to: {RESULTS_CSV}, {RESULTS_JSON}, and {METRICS_NPZ}\")\n",
    "\n",
    "# ─── OPTIMIZED EVALUATION FUNCTION ────────────────────────────────────────────\n",
    "@torch.no_grad()  # More efficient than using context manager in a loop\n",
    "def process_batch(batch_data):\n",
    "    encoding, gts, paths = batch_data  # Unpack the data from the dataloader\n",
    "    \n",
    "    # Move input data to GPU with error handling\n",
    "    try:\n",
    "        encoding = {k: v.to(DEVICE, non_blocking=True) for k, v in encoding.items()}\n",
    "    except Exception as e:\n",
    "        print(f\"Error moving input tensors to device: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Forward pass \n",
    "    try:\n",
    "        outs = MODEL.generate(**encoding)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in model generation: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Decode predictions\n",
    "    preds = [PROCESSOR.decode(o, skip_special_tokens=True).strip() for o in outs]\n",
    "    \n",
    "    # Compute metrics efficiently (vectorized when possible)\n",
    "    em_arr = np.array([int(p.lower() == g.lower()) for p, g in zip(preds, gts)])\n",
    "    \n",
    "    # F1 scores\n",
    "    f1_arr = np.zeros(len(preds))\n",
    "    for i, (p, g) in enumerate(zip(preds, gts)):\n",
    "        try:\n",
    "            f1_arr[i] = f1_score([g], [p], average='micro', zero_division=0)\n",
    "        except Exception:\n",
    "            f1_arr[i] = 0\n",
    "    \n",
    "    # BERT scores with batching and error handling\n",
    "    try:\n",
    "        P, R, F1 = bert_score(preds, gts, lang='en', verbose=False, batch_size=len(preds))\n",
    "        P, R, F1 = P.cpu().numpy(), R.cpu().numpy(), F1.cpu().numpy()\n",
    "    except Exception as e:\n",
    "        print(f\"BERT score error: {e}, using zeros\")\n",
    "        P = R = F1 = np.zeros(len(preds))\n",
    "    \n",
    "    # Sentence embeddings with error handling\n",
    "    try:\n",
    "        emb_gt = SENT_MODEL.encode(gts, convert_to_tensor=True, show_progress_bar=False)\n",
    "        emb_pr = SENT_MODEL.encode(preds, convert_to_tensor=True, show_progress_bar=False)\n",
    "        sent_sim = util.cos_sim(emb_gt, emb_pr).diag().cpu().numpy()\n",
    "        cos_sim = 1 - cdist(emb_gt.cpu().numpy(), emb_pr.cpu().numpy(), metric='cosine').diagonal()\n",
    "    except Exception as e:\n",
    "        print(f\"Embedding error: {e}, using zeros\")\n",
    "        sent_sim = cos_sim = np.zeros(len(preds))\n",
    "    \n",
    "    # Store all metrics\n",
    "    global printed, all_em, all_f1_tok, all_bert_p, all_bert_r, all_bert_f1, all_sent, all_cos, sample_data\n",
    "    \n",
    "    all_em.extend(em_arr.tolist())\n",
    "    all_f1_tok.extend(f1_arr.tolist())\n",
    "    all_bert_p.extend(P.tolist())\n",
    "    all_bert_r.extend(R.tolist())\n",
    "    all_bert_f1.extend(F1.tolist())\n",
    "    all_sent.extend(sent_sim.tolist())\n",
    "    all_cos.extend(cos_sim.tolist())\n",
    "    \n",
    "    # Store full sample data for each example\n",
    "    for i, path in enumerate(paths):\n",
    "        sample_data.append({\n",
    "            \"path\": path,\n",
    "            \"ground_truth\": gts[i],\n",
    "            \"prediction\": preds[i],\n",
    "            \"exact_match\": em_arr[i],\n",
    "            \"f1_token\": f1_arr[i],\n",
    "            \"bert_p\": float(P[i]),\n",
    "            \"bert_r\": float(R[i]),\n",
    "            \"bert_f1\": float(F1[i]),\n",
    "            \"sent_sim\": float(sent_sim[i]),\n",
    "            \"cos_sim\": float(cos_sim[i])\n",
    "        })\n",
    "    \n",
    "    # Print samples\n",
    "    for i in range(len(preds)):\n",
    "        if printed < PRINT_LIMIT:\n",
    "            print(f\"\\nSample {printed+1}\")\n",
    "            print(f\" GT: {gts[i]}\")\n",
    "            print(f\" P:  {preds[i]}\")\n",
    "            printed += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return True\n",
    "\n",
    "# ─── STREAMLINED EVALUATION LOOP WITH TIME TRACKING ──────────────────────────────────────────────────\n",
    "start_time = time.time()\n",
    "total_batches = len(loader)\n",
    "\n",
    "print(f\"Starting evaluation of {total_batches} batches...\")\n",
    "print(f\"Results will be saved to {RESULTS_CSV}, {RESULTS_JSON}, and {METRICS_NPZ}\")\n",
    "\n",
    "# Process all batches - note that loader already yields the batch data\n",
    "for batch_idx, batch_data in tqdm(enumerate(loader), \n",
    "                                desc=\"Evaluating\", \n",
    "                                unit=\"batch\", \n",
    "                                dynamic_ncols=True,\n",
    "                                total=total_batches,\n",
    "                                bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\"):\n",
    "    \n",
    "    # Process the current batch data\n",
    "    success = process_batch(batch_data)\n",
    "    if not success:\n",
    "        print(f\"Batch {batch_idx} processing failed, skipping to next batch\")\n",
    "        continue\n",
    "        \n",
    "    # Force Python's garbage collector to free memory periodically\n",
    "    if (batch_idx + 1) % 10 == 0:\n",
    "        import gc\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # Also print estimated time remaining every 10 batches\n",
    "        elapsed = time.time() - start_time\n",
    "        progress = (batch_idx + 1) / total_batches\n",
    "        if progress > 0:\n",
    "            estimated_total = elapsed / progress\n",
    "            remaining = estimated_total - elapsed\n",
    "            remaining_min = remaining / 60\n",
    "            elapsed_min = elapsed / 60\n",
    "            print(f\"Progress: {progress:.1%} | Elapsed: {elapsed_min:.1f} min | Remaining: {remaining_min:.1f} min\")\n",
    "\n",
    "# Save all results at the end\n",
    "save_results()\n",
    "\n",
    "# ─── FINAL SUMMARY ────────────────────────────────────────────────────────────\n",
    "print(\"\\n=== OVERALL METRICS ===\")\n",
    "print(f\"Exact Match:           {np.mean(all_em):.4f}\")\n",
    "print(f\"Token-level F1:        {np.mean(all_f1_tok):.4f}\")\n",
    "print(f\"BERT-Score P/R/F1:     {np.mean(all_bert_p):.4f}/{np.mean(all_bert_r):.4f}/{np.mean(all_bert_f1):.4f}\")\n",
    "print(f\"Sentence Similarity:   {np.mean(all_sent):.4f}\")\n",
    "print(f\"Cosine Similarity:     {np.mean(all_cos):.4f}\")\n",
    "print(f\"Total samples:         {len(all_em)}\")\n",
    "print(f\"Total execution time:  {(time.time() - start_time) / 60:.2f} minutes\")\n",
    "\n",
    "# Visualize the distribution of metrics\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    metrics = [\n",
    "        (\"Exact Match\", all_em),\n",
    "        (\"Token F1\", all_f1_tok), \n",
    "        (\"BERT F1\", all_bert_f1),\n",
    "        (\"Sentence Sim\", all_sent)\n",
    "    ]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i, (name, values) in enumerate(metrics):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        plt.hist(values, bins=20)\n",
    "        plt.title(f\"{name} (mean: {np.mean(values):.4f})\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"vqa_metrics_distribution.png\")\n",
    "    print(\"Visualization saved to: vqa_metrics_distribution.png\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not create visualization: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7355429,
     "sourceId": 11717591,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7364417,
     "sourceId": 11731432,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 295.01637,
   "end_time": "2025-05-17T09:01:42.683164",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-17T08:56:47.666794",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
